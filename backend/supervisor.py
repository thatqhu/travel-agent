import os
from typing import Literal
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, MessagesState, START
from langgraph.types import Command
from langchain_core.messages import HumanMessage
from pydantic import SecretStr
from agents.hotel_team import hotel_graph
from langchain.agents import create_agent
from langchain_community.tools.tavily_search import TavilySearchResults

api_key_val = os.environ.get("DASHSCOPE_API_KEY")
if not api_key_val:
    raise ValueError("DASHSCOPE_API_KEY is not set")
llm = ChatOpenAI(
    model="qwen-plus",
    api_key=SecretStr(api_key_val),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    temperature=0.5
)


class TravelState(MessagesState):
    next: str

itinerary_searcher = create_agent(
    llm
)


def call_hotel_team(state: TravelState) -> Command[Literal["supervisor"]]:
    """è°ƒç”¨é…’åº—å›¢é˜Ÿ"""
    response = hotel_graph.invoke({"messages": state["messages"]})
    return Command(
        update={
            "messages": [
                HumanMessage(
                    content=f"ğŸ¨ [é…’åº—å›¢é˜Ÿå®Œæˆ]\n\n{response['messages'][-1].content}",
                    name="hotel_team"
                )
            ]
        },
        goto="supervisor"
    )

def call_itinerary_team(state: TravelState) -> Command[Literal["supervisor"]]:
    """è°ƒç”¨è¡Œç¨‹å›¢é˜Ÿ"""
    system_prompt = (
        "ä½ æ˜¯è¡Œç¨‹è®¾è®¡å¸ˆï¼Œè´Ÿè´£è®¾è®¡å®Œæ•´çš„æ¯æ—¥è¡Œç¨‹ï¼ŒåŒ…æ‹¬äº¤é€šã€é¤é¥®å’Œé¢„ç®—è§„åˆ’ã€‚ç”¨ä¸“ä¸šä¸”å‹å¥½çš„è¯­æ°”, ç®€çŸ­æ€»ç»“ä¸€ä¸‹."
    )
    messages = [{"role": "system", "content": system_prompt}] + state["messages"]
    response = itinerary_searcher.invoke({"messages": messages})

    return Command(
        update={
            "messages": [
                HumanMessage(
                    content=f"ğŸ—“ï¸ [è¡Œç¨‹å›¢é˜Ÿå®Œæˆ]\n\n{response['messages'][-1].content}",
                    name="itinerary_team"
                )
            ]
        },
        goto="supervisor"
    )

def generate_final_plan(state: TravelState) -> Command[Literal["__end__"]]:
    """ç”Ÿæˆæœ€ç»ˆæ—…è¡Œè®¡åˆ’"""
    messages = [
        {"role": "system", "content":
         "ä½ æ˜¯ä¸“ä¸šçš„æ—…è¡Œé¡¾é—®ã€‚æ ¹æ®é…’åº—å›¢é˜Ÿå’Œè¡Œç¨‹å›¢é˜Ÿçš„å·¥ä½œç»“æœï¼Œæ•´åˆç”Ÿæˆä¸€ä»½ç®€çŸ­çš„æ—…è¡Œè®¡åˆ’ã€‚ç”¨æ¸…æ™°çš„æ ¼å¼å’Œå‹å¥½çš„è¯­æ°”å‘ˆç°."},
    ] + state["messages"]

    response = llm.invoke(messages)

    return Command(
        update={
            "messages": [
                HumanMessage(
                    content=f"âœˆï¸ [æœ€ç»ˆæ—…è¡Œè®¡åˆ’]\n\n{response.content}",
                    name="final_planner"
                )
            ]
        },
        goto="__end__"
    )

def top_supervisor(state: TravelState) -> Command:
    """é¡¶å±‚ç›‘ç£è€…"""
    from typing_extensions import TypedDict

    class Router(TypedDict):
        next: Literal["hotel_team", "itinerary_team", "final_plan", "FINISH"]

    messages = [
        {"role": "system", "content":
         "ä½ æ˜¯æ—…è¡Œè§„åˆ’æ€»ç›‘ã€‚åè°ƒ hotel_team(é…’åº—æœç´¢) å’Œ itinerary_team(è¡Œç¨‹è§„åˆ’)ã€‚"
         "å·¥ä½œæµç¨‹ï¼š1. å…ˆè®©hotel_teamæœç´¢é…’åº—. 2. ç„¶åè®©itinerary_teamè§„åˆ’è¡Œç¨‹. "
         "3. æœ€åè°ƒç”¨final_planæ•´åˆç”Ÿæˆå®Œæ•´è®¡åˆ’. 4. æ²¡æœ‰ç»“æŸè¿”å›jsonæ ¼å¼æ•°æ®, ç¤ºä¾‹: {'next': 'hotel_team'}. 5. è¿”å›FINISHç»“æŸã€‚"},
    ] + state["messages"]

    response = llm.with_structured_output(Router).invoke(messages)
    goto = response["next"]

    if goto == "FINISH":
        goto = "__end__"

    return Command(goto=goto, update={"next": goto})

# æ„å»ºé¡¶å±‚å›¾
travel_builder = StateGraph(TravelState)
travel_builder.add_node("supervisor", top_supervisor)
travel_builder.add_node("hotel_team", call_hotel_team)
travel_builder.add_node("itinerary_team", call_itinerary_team)
travel_builder.add_node("final_plan", generate_final_plan)
travel_builder.add_edge(START, "supervisor")
travel_graph = travel_builder.compile()
